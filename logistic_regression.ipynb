{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997b721d",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "We will discuss:\n",
    "\n",
    "- How MLE fits in when it comes to estimating coefficients\n",
    "- Log-odds\n",
    "- Odds ratios\n",
    "- and assumptions regarding MLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from main import preprocess_df\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "\n",
    "my_df = pd.read_csv(\n",
    "    \"./datasets/lc_data_2007_to_2018.csv\",\n",
    "    low_memory=False,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=100000,  # only looking at 100k rows right now for performance\n",
    ")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "cleaned_df = preprocess_df(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7149541",
   "metadata": {},
   "source": [
    "Logistic regression is when we calculate a score for how likely something is to happen, via a linear equation. In our case, we want to predict the probability of default from all the factors contained in the dataset. But since we're using a linear equation, this score can range from $-\\infin$ to $\\infin$, and we could end up with a value that makes no sense probabilistically, like $1.2$. To account for this, we use the sigmoid function:\n",
    "\n",
    "##### $S(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "This function takes in values from $-\\infin$ to $\\infin$ and outputs only values between 0 and 1, perfect for probability.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
