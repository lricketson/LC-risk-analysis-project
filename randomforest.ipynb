{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273b6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from main import preprocess_df\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "\n",
    "my_df = pd.read_csv(\n",
    "    \"./datasets/lc_data_2007_to_2018.csv\",\n",
    "    low_memory=False,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=100000,  # only looking at 100k rows right now for performance\n",
    ")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "cleaned_df = preprocess_df(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb836fb",
   "metadata": {},
   "source": [
    "## Random Forest Classification for Predicting Loan Default Probability\n",
    "\n",
    "Random Forest Classifier is another model that can predict the probability of a borrower defaulting on a loan. Instead of minimising an error function like logistic regression, RF takes thousands of decision trees and trains them on random samples of the data. Some trees are limited on what they're allowed to use as data, e.g. some trees are intentionally kept from receiving FICO scores, so these trees are forced to find less obvious patterns in debt or income, for example. This decorrelates the trees and gives a wider, more holistic understanding within the forest. Then when testing, we pose the same situation to all trees at once, have them go through their trained decision process, and take the average of their answers. The probability of default is the proportion of yes answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39563327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = cleaned_df.loc[:, cleaned_df.columns != \"did_default\"]\n",
    "y = cleaned_df.loc[:, cleaned_df.columns == \"did_default\"]\n",
    "\n",
    "y = (\n",
    "    y.values.ravel()\n",
    ")  # turns y from a 1-column DataFrame to just a list; in essence the same thing but sklearn prefers a list\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_X_train = imputer.fit_transform(X_train)\n",
    "imputed_X_test = imputer.transform(X_test)\n",
    "# no need to do scaling of X because random forest doesn't care about scale, it just splits\n",
    "# like 'is income > 50,000' without caring how big 50,000 is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c86b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With class weights: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.98      0.89     14028\n",
      "        True       0.58      0.10      0.18      3551\n",
      "\n",
      "    accuracy                           0.80     17579\n",
      "   macro avg       0.70      0.54      0.53     17579\n",
      "weighted avg       0.77      0.80      0.74     17579\n",
      "\n",
      "ROC AUC score: 0.7334239876043062\n",
      "With class weights: balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.70      0.78     14028\n",
      "        True       0.35      0.63      0.45      3551\n",
      "\n",
      "    accuracy                           0.69     17579\n",
      "   macro avg       0.62      0.67      0.62     17579\n",
      "weighted avg       0.78      0.69      0.72     17579\n",
      "\n",
      "ROC AUC score: 0.7310768895487378\n"
     ]
    }
   ],
   "source": [
    "weights = [None, \"balanced\"]\n",
    "for w in weights:\n",
    "    rfc_model = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=10, random_state=42, class_weight=w\n",
    "    )\n",
    "    rfc_model.fit(imputed_X_train, y_train)\n",
    "    rfc_probs = rfc_model.predict_proba(imputed_X_test)[:, 1]\n",
    "    rfc_preds = rfc_model.predict(imputed_X_test)\n",
    "    print(f\"With class weights: {w}\")\n",
    "    cr = classification_report(y_test, rfc_preds)\n",
    "    print(cr)\n",
    "    roc_auc = roc_auc_score(y_test, rfc_probs)\n",
    "    print(f\"ROC AUC score: {round(roc_auc, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902030b0",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Like with logistic regression, the model realised that since there were many fewer defaulters, it could guess 'No default' to almost everyone and get a very high accuracy score. In the model's world of minimising error, this is a good outcome, but in the real world it's catastrophic, as lots of money would be lost.\n",
    "\n",
    "#### Without class weighting\n",
    "\n",
    "```\n",
    "Classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.81      0.98      0.89     14028\n",
    "        True       0.58      0.10      0.18      3551\n",
    "\n",
    "    accuracy                           0.80     17579\n",
    "   macro avg       0.70      0.54      0.53     17579\n",
    "weighted avg       0.77      0.80      0.74     17579\n",
    "\n",
    "ROC AUC score: 0.733\n",
    "```\n",
    "\n",
    "Just as before, the model gets good metrics on non-defaulters but does terribly on defaulters.\n",
    "\n",
    "#### Without class weighting\n",
    "\n",
    "```\n",
    "Classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.88      0.70      0.78     14028\n",
    "        True       0.35      0.63      0.45      3551\n",
    "\n",
    "    accuracy                           0.69     17579\n",
    "   macro avg       0.62      0.67      0.62     17579\n",
    "weighted avg       0.78      0.69      0.72     17579\n",
    "\n",
    "ROC AUC score: 0.731\n",
    "```\n",
    "\n",
    "With balanced class weights, the model values correctly rejecting defaulters. Thus it employs a more conservative approach, rejecting many more people, some of whom would've paid the loan back in full, as shown by the drop in precision on defaulters (0.58 to 0.35). But the recall jumped up from a dreadful 0.10 to 0.63, a huge increase, meaning that many fewer defaulters are being approved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
